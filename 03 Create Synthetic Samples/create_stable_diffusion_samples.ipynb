{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647afd5a-43e1-4d3a-91d9-7ff622b7e7f4",
   "metadata": {},
   "source": [
    "# Notebook: Create Synthetic Samples With Trained SD Model\n",
    "\n",
    "This notebook is used to create new images using the trained SD Model.\n",
    "<br>\n",
    "**Contributors:** Nils Hellwig "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52edc58e-2271-452d-9713-b73962b0a6cb",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "78e7cffa-ef1e-4af1-9e76-8d9d63b59593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f6ad2-a7db-473c-8bbc-c3e2f08c61e5",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "395f67fb-c151-4b58-b54f-e88618a0082c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_METADATA_PATH = \"../Datasets/raw_dataset.csv\"\n",
    "RAW_DATASET_PATH = \"../Datasets/raw_dataset/\"\n",
    "DATASET_PATH = \"../Datasets/dataset/\"\n",
    "SYNTH_DATASET_PATH = \"../Datasets/synth_dataset/\"\n",
    "SEED = 42\n",
    "N_EXAMPLES_FOR_LABEL = 1000\n",
    "MODEL_PATH = \"/mnt/data/stable_diffusion_2_skin/\"\n",
    "OUTPUT_CSV = \"/Datasets/generative_prompts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3793a067-3dac-4d87-8ce2-82e561897508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_PROMPTS = {\n",
    "                 \"akiec\": \"Actinic keratoses and intraepithelial carcinoma / Bowen's disease\",\n",
    "                 \"bcc\":\"basal cell carcinoma\",\n",
    "                 \"df\": \"dermatofibroma\",\n",
    "                 \"mel\": \"melanoma\",\n",
    "                 \"nv\": \"melanocytic nevi\",\n",
    "                 \"vasc\": \"vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage\",\n",
    "                 \"bkl\": \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7016cc-ce0a-4938-8cdd-2c34f8ec7408",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "678c5ea1-4352-4070-b908-108eb9a732f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ebb9ddcf-c426-435b-af2d-f21e077fa8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hen58277/anaconda3/envs/ml_env/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.15.0.dev0\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPFeatureExtractor\"\n",
       "  ],\n",
       "  \"requires_safety_checker\": false,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DDIMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(MODEL_PATH, torch_dtype=torch.float16, use_auth_token=True, safety_checker = None)\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8b9bb-9f7e-43d2-aac5-8320149ca0ea",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff01c78-f3a4-4b06-a28f-4e8d8af3352b",
   "metadata": {},
   "source": [
    "### Load Train Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c4e6cdef-dada-42f6-8205-36c200c63110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8050</td>\n",
       "      <td>HAM_0005972</td>\n",
       "      <td>ISIC_0033319</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>dataset/ISIC_0033319.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4898</td>\n",
       "      <td>HAM_0004902</td>\n",
       "      <td>ISIC_0030823</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>dataset/ISIC_0030823.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9695</td>\n",
       "      <td>HAM_0005282</td>\n",
       "      <td>ISIC_0028730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>dataset/ISIC_0028730.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4090</td>\n",
       "      <td>HAM_0000475</td>\n",
       "      <td>ISIC_0027299</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>dataset/ISIC_0027299.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8625</td>\n",
       "      <td>HAM_0000949</td>\n",
       "      <td>ISIC_0032444</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>dataset/ISIC_0032444.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>2360</td>\n",
       "      <td>HAM_0000940</td>\n",
       "      <td>ISIC_0032692</td>\n",
       "      <td>vasc</td>\n",
       "      <td>histo</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>dataset/ISIC_0032692.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>3409</td>\n",
       "      <td>HAM_0005629</td>\n",
       "      <td>ISIC_0029317</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>dataset/ISIC_0029317.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>8736</td>\n",
       "      <td>HAM_0004025</td>\n",
       "      <td>ISIC_0025983</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>dataset/ISIC_0025983.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>2399</td>\n",
       "      <td>HAM_0004542</td>\n",
       "      <td>ISIC_0027256</td>\n",
       "      <td>vasc</td>\n",
       "      <td>consensus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>dataset/ISIC_0027256.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>4693</td>\n",
       "      <td>HAM_0006927</td>\n",
       "      <td>ISIC_0026312</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>dataset/ISIC_0026312.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8012 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    lesion_id      image_id     dx    dx_type   age     sex  \\\n",
       "0           8050  HAM_0005972  ISIC_0033319     nv      histo  35.0  female   \n",
       "1           4898  HAM_0004902  ISIC_0030823     nv  follow_up  40.0    male   \n",
       "2           9695  HAM_0005282  ISIC_0028730  akiec      histo  65.0    male   \n",
       "3           4090  HAM_0000475  ISIC_0027299     nv  follow_up  40.0    male   \n",
       "4           8625  HAM_0000949  ISIC_0032444     nv      histo  65.0    male   \n",
       "...          ...          ...           ...    ...        ...   ...     ...   \n",
       "8007        2360  HAM_0000940  ISIC_0032692   vasc      histo  35.0  female   \n",
       "8008        3409  HAM_0005629  ISIC_0029317     nv  follow_up  45.0  female   \n",
       "8009        8736  HAM_0004025  ISIC_0025983     nv      histo  20.0  female   \n",
       "8010        2399  HAM_0004542  ISIC_0027256   vasc  consensus   0.0  female   \n",
       "8011        4693  HAM_0006927  ISIC_0026312     nv  follow_up  50.0  female   \n",
       "\n",
       "         localization        dataset                  filepath  \n",
       "0     lower extremity   vidir_modern  dataset/ISIC_0033319.jpg  \n",
       "1               trunk  vidir_molemax  dataset/ISIC_0030823.jpg  \n",
       "2     lower extremity      rosendahl  dataset/ISIC_0028730.jpg  \n",
       "3     lower extremity  vidir_molemax  dataset/ISIC_0027299.jpg  \n",
       "4                back      rosendahl  dataset/ISIC_0032444.jpg  \n",
       "...               ...            ...                       ...  \n",
       "8007  lower extremity   vidir_modern  dataset/ISIC_0032692.jpg  \n",
       "8008  upper extremity  vidir_molemax  dataset/ISIC_0029317.jpg  \n",
       "8009          abdomen      rosendahl  dataset/ISIC_0025983.jpg  \n",
       "8010             back   vidir_modern  dataset/ISIC_0027256.jpg  \n",
       "8011  lower extremity  vidir_molemax  dataset/ISIC_0026312.jpg  \n",
       "\n",
       "[8012 rows x 10 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file as a DataFrame\n",
    "train_df = pd.read_csv(DATASET_PATH + \"train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e6a234b0-23f9-4d07-8194-9a3b6ab862d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_generative_prompts = pd.DataFrame({\n",
    "    'file_name': [], \n",
    "    'text': [],\n",
    "    'localization': [],\n",
    "    'sex': [],\n",
    "    'age': [],\n",
    "    'dx': []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2014f124-f362-4756-bbc8-a02eda84573f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def get_random_value(df, column_name):\n",
    "    column = df[column_name]\n",
    "    #print(column)\n",
    "    random_value = np.random.choice(column)\n",
    "    return random_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "758a1b36-0191-4287-81d7-1165fd56b360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc = train_df[\"dx\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "134ff3c2-1fab-4a06-8803-2f260e2a7252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, N_EXAMPLES_FOR_LABEL):\n",
    "    for key, value in vc.items():\n",
    "        df_dx = train_df[train_df[\"dx\"] == key]\n",
    "        sex = get_random_value(df_dx, \"sex\")\n",
    "        localization = get_random_value(df_dx, \"localization\")\n",
    "        age = get_random_value(df_dx, \"age\")\n",
    "        \n",
    "        prompt = LABEL_PROMPTS[key] + \" \" + sex + \" \" + localization + \" \" + str(age)\n",
    "        file_name = key + \"/\" + key + \"_\" + str(i) + \".jpg\"\n",
    "        \n",
    "        new_row = {'file_name': file_name, 'text': prompt, 'sex': sex, 'localization': localization, 'age': age, 'dx': key}\n",
    "        df_generative_prompts = pd.concat([df_generative_prompts, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e466d802-ca36-466d-9796-982a35720fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>localization</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nv/nv_0.jpg</td>\n",
       "      <td>melanocytic nevi female abdomen 80.0</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mel/mel_0.jpg</td>\n",
       "      <td>melanoma male upper extremity 80.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>mel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bkl/bkl_0.jpg</td>\n",
       "      <td>benign keratosis-like lesions (solar lentigine...</td>\n",
       "      <td>face</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bcc/bcc_0.jpg</td>\n",
       "      <td>basal cell carcinoma female abdomen 80.0</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>bcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akiec/akiec_0.jpg</td>\n",
       "      <td>Actinic keratoses and intraepithelial carcinom...</td>\n",
       "      <td>neck</td>\n",
       "      <td>male</td>\n",
       "      <td>75.0</td>\n",
       "      <td>akiec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>bkl/bkl_999.jpg</td>\n",
       "      <td>benign keratosis-like lesions (solar lentigine...</td>\n",
       "      <td>face</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>bcc/bcc_999.jpg</td>\n",
       "      <td>basal cell carcinoma male back 70.0</td>\n",
       "      <td>back</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>bcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>akiec/akiec_999.jpg</td>\n",
       "      <td>Actinic keratoses and intraepithelial carcinom...</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>akiec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>vasc/vasc_999.jpg</td>\n",
       "      <td>vascular lesions (angiomas, angiokeratomas, py...</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>female</td>\n",
       "      <td>70.0</td>\n",
       "      <td>vasc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>df/df_999.jpg</td>\n",
       "      <td>dermatofibroma female lower extremity 50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>df</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name                                               text  \\\n",
       "0             nv/nv_0.jpg               melanocytic nevi female abdomen 80.0   \n",
       "1           mel/mel_0.jpg                 melanoma male upper extremity 80.0   \n",
       "2           bkl/bkl_0.jpg  benign keratosis-like lesions (solar lentigine...   \n",
       "3           bcc/bcc_0.jpg           basal cell carcinoma female abdomen 80.0   \n",
       "4       akiec/akiec_0.jpg  Actinic keratoses and intraepithelial carcinom...   \n",
       "...                   ...                                                ...   \n",
       "6995      bkl/bkl_999.jpg  benign keratosis-like lesions (solar lentigine...   \n",
       "6996      bcc/bcc_999.jpg                basal cell carcinoma male back 70.0   \n",
       "6997  akiec/akiec_999.jpg  Actinic keratoses and intraepithelial carcinom...   \n",
       "6998    vasc/vasc_999.jpg  vascular lesions (angiomas, angiokeratomas, py...   \n",
       "6999        df/df_999.jpg         dermatofibroma female lower extremity 50.0   \n",
       "\n",
       "         localization     sex   age     dx  \n",
       "0             abdomen  female  80.0     nv  \n",
       "1     upper extremity    male  80.0    mel  \n",
       "2                face  female  40.0    bkl  \n",
       "3             abdomen  female  80.0    bcc  \n",
       "4                neck    male  75.0  akiec  \n",
       "...               ...     ...   ...    ...  \n",
       "6995             face    male  80.0    bkl  \n",
       "6996             back    male  70.0    bcc  \n",
       "6997  lower extremity    male  60.0  akiec  \n",
       "6998  upper extremity  female  70.0   vasc  \n",
       "6999  lower extremity  female  50.0     df  \n",
       "\n",
       "[7000 rows x 6 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generative_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca8d3a-f847-48fb-b82b-2660540b98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generative_prompts.to_csv(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9b3ba824-a9e6-4ecb-8c2e-af1fb02df488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████                                                                    | 15/50 [00:04<00:10,  3.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m image\u001b[38;5;241m.\u001b[39msave(SYNTH_DATASET_PATH \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:667\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.__call__\u001b[0;34m(self, prompt, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m latent_model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mscale_model_input(latent_model_input, t)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_classifier_free_guidance:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:631\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, down_block_additional_residuals, mid_block_additional_residual, return_dict)\u001b[0m\n\u001b[1;32m    628\u001b[0m     upsample_size \u001b[38;5;241m=\u001b[39m down_block_res_samples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(upsample_block, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_cross_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m upsample_block\u001b[38;5;241m.\u001b[39mhas_cross_attention:\n\u001b[0;32m--> 631\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mupsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mres_hidden_states_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     sample \u001b[38;5;241m=\u001b[39m upsample_block(\n\u001b[1;32m    642\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39msample, temb\u001b[38;5;241m=\u001b[39memb, res_hidden_states_tuple\u001b[38;5;241m=\u001b[39mres_samples, upsample_size\u001b[38;5;241m=\u001b[39mupsample_size\n\u001b[1;32m    643\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:1813\u001b[0m, in \u001b[0;36mCrossAttnUpBlock2D.forward\u001b[0;34m(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, cross_attention_kwargs, upsample_size, attention_mask)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1812\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m resnet(hidden_states, temb)\n\u001b[0;32m-> 1813\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m   1819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1820\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/diffusers/models/transformer_2d.py:257\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, class_labels, cross_attention_kwargs, return_dict)\u001b[0m\n\u001b[1;32m    255\u001b[0m         inner_dim \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    256\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch, height \u001b[38;5;241m*\u001b[39m width, inner_dim)\n\u001b[0;32m--> 257\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_vectorized:\n\u001b[1;32m    259\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_image_embedding(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in df_generative_prompts.iterrows():\n",
    "    file_name = row['file_name']\n",
    "    text = row['text']\n",
    "    try:\n",
    "        os.makedirs(SYNTH_DATASET_PATH + row['dx'])\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    image = pipe(prompt=text).images[0]\n",
    "    image.save(SYNTH_DATASET_PATH + row['file_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
